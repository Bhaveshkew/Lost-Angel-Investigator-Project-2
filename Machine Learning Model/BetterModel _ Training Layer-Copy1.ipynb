{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf0fe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4764 files belonging to 80 classes.\n",
      "Found 1602 files belonging to 80 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "train_dir = \"output/train/\"\n",
    "test_dir = \"output/val/\"\n",
    "\n",
    "\n",
    "\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                                label_mode=\"categorical\",\n",
    "                                                                                image_size=IMG_SIZE)\n",
    "                                                                                \n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                                label_mode=\"categorical\",\n",
    "                                                                image_size=IMG_SIZE,\n",
    "                                                                shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d999d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 224, 224, 3), (None, 80)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99ae233",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"better_model_checkpoint\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                         save_weights_only=True, # save only the model weights\n",
    "                                                         monitor=\"val_accuracy\", # save the model weights which score the best validation accuracy\n",
    "                                                         save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac175785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.layers.experimental import preprocessing\n",
    "# from tensorflow.keras.models import Sequential\n",
    "\n",
    "# # original_data = Sequential([\n",
    "# #   preprocessing.RandomRotation(0), \n",
    "# # ], name=\"original_data\")\n",
    "\n",
    "# data_augmentation = Sequential([\n",
    "#     preprocessing.RandomRotation(0),\n",
    "#     preprocessing.RandomFlip(\"horizontal\"),\n",
    "#     preprocessing.RandomRotation(0.2),  \n",
    "#     preprocessing.RandomHeight(0.2),\n",
    "#     preprocessing.RandomWidth(0.2),\n",
    "#     preprocessing.RandomZoom(0.2),\n",
    "#     preprocessing.RandomContrast(0.1),\n",
    "# ], name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813825b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
    "\n",
    "x = base_model(inputs, training=False) \n",
    "x = layers.GlobalAveragePooling2D(name=\"global_average_pooling\")(x) \n",
    "outputs = layers.Dense(len(train_data.class_names), activation=\"softmax\", name=\"output_layer\")(x) \n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06b45717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n",
      "_________________________________________________________________\n",
      "global_average_pooling (Glob (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 80)                102480    \n",
      "=================================================================\n",
      "Total params: 4,152,051\n",
      "Trainable params: 102,480\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38830d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "149/149 [==============================] - 59s 376ms/step - loss: 3.4971 - accuracy: 0.2981 - val_loss: 2.6657 - val_accuracy: 0.5693\n",
      "Epoch 2/10\n",
      "149/149 [==============================] - 54s 359ms/step - loss: 2.1260 - accuracy: 0.7275 - val_loss: 1.7746 - val_accuracy: 0.7878\n",
      "Epoch 3/10\n",
      "149/149 [==============================] - 52s 352ms/step - loss: 1.4114 - accuracy: 0.8699 - val_loss: 1.2896 - val_accuracy: 0.8614\n",
      "Epoch 4/10\n",
      "149/149 [==============================] - 51s 345ms/step - loss: 1.0041 - accuracy: 0.9223 - val_loss: 0.9829 - val_accuracy: 0.9032\n",
      "Epoch 5/10\n",
      "149/149 [==============================] - 52s 351ms/step - loss: 0.7470 - accuracy: 0.9477 - val_loss: 0.7880 - val_accuracy: 0.9282\n",
      "Epoch 6/10\n",
      "149/149 [==============================] - 53s 353ms/step - loss: 0.5817 - accuracy: 0.9662 - val_loss: 0.6558 - val_accuracy: 0.9376\n",
      "Epoch 7/10\n",
      "149/149 [==============================] - 53s 354ms/step - loss: 0.4671 - accuracy: 0.9736 - val_loss: 0.5493 - val_accuracy: 0.9488\n",
      "Epoch 8/10\n",
      "149/149 [==============================] - 53s 354ms/step - loss: 0.3837 - accuracy: 0.9805 - val_loss: 0.4722 - val_accuracy: 0.9576\n",
      "Epoch 9/10\n",
      "149/149 [==============================] - 52s 349ms/step - loss: 0.3189 - accuracy: 0.9857 - val_loss: 0.4157 - val_accuracy: 0.9613\n",
      "Epoch 10/10\n",
      "149/149 [==============================] - 52s 350ms/step - loss: 0.2694 - accuracy: 0.9901 - val_loss: 0.3681 - val_accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit\n",
    "history_base_model = model.fit(train_data,\n",
    "                                           epochs=10, \n",
    "                                           validation_data=test_data,\n",
    "                                           validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1431bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Refreeze every layer except for the last 5\n",
    "for layer in base_model.layers[:-5]:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f3619",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4), # 10x lower learning rate than default\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e83ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 31\n",
    "\n",
    "history_model_fine_tune = model.fit(train_data,\n",
    "                                                     epochs=fine_tune_epochs,\n",
    "                                                     validation_data=test_data,\n",
    "                                                     validation_steps=len(test_data),\n",
    "                                                     initial_epoch=history_base_model.epoch[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# IMAGE_SHAPE = (224, 224)\n",
    "# IMAGE_SHAPE+(3,)\n",
    "# test_dir = \"C:\\\\Users\\\\bhave\\\\Project-1\\\\Class25_Dataset\\\\train\\\\a\\\\2.jpeg\"\n",
    "# img = cv2.imread(test_dir)\n",
    "# img_resize = cv2.resize(img , IMAGE_SHAPE)\n",
    "# predicted = model.predict(np.array([img_resize]))\n",
    "# ind = np.argmax(predicted , axis = 1)\n",
    "# index = ind[0]\n",
    "# print(index)\n",
    "# cv2.imshow('detected', img)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13ef70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"95.19_better_model.json\" , \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"95.19_better_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec29c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "model_file = open(\"ndtry_better_model.json\", \"r\")\n",
    "model_json = model_file.read()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"ndtry_better_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99965df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "IMAGE_SHAPE+(3,)\n",
    "test_dir = \"C:\\\\Users\\\\bhave\\\\Project-1\\\\New Versions\\\\output\\\\val\\\\S10_9yoM\\\\S102_9yoF_Angry_far right_4005.JPG\"\n",
    "img = cv2.imread(test_dir)\n",
    "img_resize = cv2.resize(img , IMAGE_SHAPE)\n",
    "predicted = model.predict(np.array([img_resize]))\n",
    "ind = np.argmax(predicted , axis = 1)\n",
    "index = ind[0]\n",
    "print(index)\n",
    "cv2.imshow('detected', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d8537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd05c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbef9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
